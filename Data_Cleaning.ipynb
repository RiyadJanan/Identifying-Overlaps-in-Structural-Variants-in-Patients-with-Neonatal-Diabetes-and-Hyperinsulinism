{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formatting Raw CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [

     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def reformat_csv(file_path):\n",
    "    # Load the CSV file with tab delimiter\n",
    "    data = pd.read_csv(file_path, delimiter='\\t', header=None)\n",
    "    \n",
    "    # Define column names based on the observed structure\n",
    "    column_names = [\"Coordinate1\", \"Orientation1\", \"Coordinate2\", \"Orientation2\", \"Read_Count\",\n",
    "                    \"Read_Width\", \"Type\", \"Proband1\", \"Proband2\", \"Parent1_2\", \"Parent1_2\", \"Parent2_1\", \"Parent2_2\"]\n",
    "    data.columns = column_names[:len(data.columns)]\n",
    "    \n",
    "    # Save the reformatted CSV file\n",
    "    new_file_path = file_path.replace('.csv', '_reformatted.csv')\n",
    "    data.to_csv(new_file_path, index=False)\n",
    "\n",
    "def reformat_all_csvs_in_directory(directory_path):\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('.csv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            reformat_csv(file_path)\n",
    "            print(f\"Reformatted: {filename}\")\n",
    "\n",
    "# Usage\n",
    "directory_path = 'Raw_Controls'  # Replace with your directory path\n",
    "reformat_all_csvs_in_directory(directory_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined CSV saved as NDM.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def combine_csvs_with_sample_ids(directory_path, output_file):\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith('_reformatted.csv'):\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # Extract Sample_ID from the filename\n",
    "            sample_id = filename.replace('_reformatted.csv', '')\n",
    "            # Read the CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Add the Sample_ID column\n",
    "            df.insert(0, 'Sample_ID', sample_id)\n",
    "            # Append to the combined dataframe\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "    # Save the combined dataframe to a new CSV file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined CSV saved as {output_file}\")\n",
    "\n",
    "# Usage\n",
    "directory_path = 'Raw_NDMs'  # Replace with your directory path\n",
    "output_file = 'NDM.csv'  # Path to save the combined CSV file\n",
    "combine_csvs_with_sample_ids(directory_path, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing GLs and Translocations (V1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered combined CSV saved as NDM_V1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_combined_csv(input_file, output_file):\n",
    "    # Load the combined CSV file\n",
    "    combined_df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Filter out translocations and variants with \"GL\" in coordinates\n",
    "    df_filtered = combined_df[~combined_df['Type'].str.contains('Translocation', na=False)]\n",
    "    df_filtered = df_filtered[~df_filtered['Coordinate1'].str.contains('GL', na=False)]\n",
    "    df_filtered = df_filtered[~df_filtered['Coordinate2'].str.contains('GL', na=False)]\n",
    "    \n",
    "    # Save the filtered dataframe to a new CSV file\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    print(f\"Filtered combined CSV saved as {output_file}\")\n",
    "\n",
    "# Usage\n",
    "input_file = 'NDM.csv'  # Replace with your input file path\n",
    "output_file = 'NDM_V1.csv'  # Replace with your desired output file path\n",
    "filter_combined_csv(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Chromosome Column (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaned and saved back to NDM_V1.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_data(df):\n",
    "    # Derive column 'chr' from column: 'Coordinate1'\n",
    "    df.insert(2, \"chr\", df[\"Coordinate1\"].str.split(\":\").str[0])\n",
    "    # Derive column 'Coordinate1_' from column: 'Coordinate1'\n",
    "    df.insert(2, \"Coordinate1_\", df[\"Coordinate1\"].str.split(\":\").str[-1])\n",
    "    # Drop column: 'chr'\n",
    "    df = df.drop(columns=['chr'])\n",
    "    # Derive column 'chr' from column: 'Coordinate1'\n",
    "    df.insert(2, \"chr\", df[\"Coordinate1\"].str.split(\":\").str[0])\n",
    "    # Derive column 'Coordinate2_' from column: 'Coordinate2'\n",
    "    df.insert(6, \"Coordinate2_\", df[\"Coordinate2\"].str.split(\":\").str[-1])\n",
    "    # Drop column: 'Coordinate1'\n",
    "    df = df.drop(columns=['Coordinate1'])\n",
    "    # Drop column: 'Coordinate2'\n",
    "    df = df.drop(columns=['Coordinate2'])\n",
    "    return df\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = 'NDM_V1.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Clean the data\n",
    "df_clean = clean_data(df.copy())\n",
    "\n",
    "# Overwrite the original CSV file with the cleaned data\n",
    "df_clean.to_csv(file_path, index=False)\n",
    "\n",
    "print(f\"Data cleaned and saved back to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding GT Column (V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DataFrame has been updated with the 'Genotype' column and saved as 'final_filtered_HI_with_genotype.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you're working with the final_filtered_NDM_hashed.csv file\n",
    "df = pd.read_csv('Controls_V1.csv')\n",
    "\n",
    "# Define a function to determine the genotype based on columns 13 and 15\n",
    "def determine_genotype(row):\n",
    "    col_13 = row['Parent1_1']  # Adjust the column name as per your DataFrame\n",
    "    col_15 = row['Parent2_1']  # Adjust the column name as per your DataFrame\n",
    "    \n",
    "    if col_13 == 0 and col_15 > 0:\n",
    "        return '0/1'\n",
    "    elif col_13 > 0 and col_15 > 0:\n",
    "        return '1/1'\n",
    "    elif col_13 > 0 and col_15 == 0:\n",
    "        return '1/0'\n",
    "    elif col_13 == 0 and col_15 == 0:\n",
    "        return '0/0'\n",
    "    else:\n",
    "        return 'N/A'  # For cases that don't match any of the conditions\n",
    "\n",
    "# Apply the function to each row of the DataFrame to create the 'Genotype' column\n",
    "df['GT'] = df.apply(determine_genotype, axis=1)\n",
    "\n",
    "df = df.drop(columns=['Proband1','Proband2','Parent1_1','Parent1_2','Parent2_1','Parent2_2'], errors='ignore')\n",
    "\n",
    "# Save the DataFrame with the new 'Genotype' column\n",
    "df.to_csv('Controls_V1.csv', index=False)\n",
    "\n",
    "print(\"The DataFrame has been updated with the 'Genotype' column and saved as 'final_filtered_HI_with_genotype.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
